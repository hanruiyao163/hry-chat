# HRY Chat Backend 配置示例
# 复制此文件为 .env 并填入实际值

# 应用配置
APP_NAME=HRY Chat
DEBUG=false

# LLM 配置
# 支持的 provider: openai / azure / anthropic / mock
LLM_PROVIDER=openai
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o-mini

# Mock 模式 - 设为 true 时使用固定回复，用于 UI 测试
MOCK_MODE=true

# CORS 配置
CORS_ORIGINS=["http://localhost:3000", "http://127.0.0.1:3000"]
